{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDrcOVDGnyDI"
      },
      "source": [
        "## About iPython Notebooks ##\n",
        "\n",
        "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
        "\n",
        " **What you need to remember:**\n",
        "\n",
        "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
        "- Write code in the designated areas using Python 3 only\n",
        "- Do not modify the code outside of the designated areas\n",
        "- In some cases you will also need to explain the results. There will also be designated areas for that. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgauGbInyDM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_FF68cfznyDO",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ce63642cafb413e7903d83d2f2cd3637",
          "grade": false,
          "grade_id": "cell-f62db6dce1ed3f2e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Assignment 2 - Decision Trees #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zq29ctnanyDO",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "29d61ce286fdb8fd61c7f8e89a9e1339",
          "grade": false,
          "grade_id": "cell-dce2e73cee9a5017",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mb4Wf4IdnyDP",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50a108d2f1e1a1ee2fde80743c0543fe",
          "grade": false,
          "grade_id": "cell-83ca2b0456fb85db",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "After this assignment you will:\n",
        "- Be able to use the scikit-learn library and train your own model from scratch.\n",
        "- Be able to train and understand decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "sLqpxgvbnyDQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "396c39a0797964c378ebb90cf18a29de",
          "grade": false,
          "grade_id": "cell-2cef6d48eea484d8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Always run this cell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "\n",
        "# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS\n",
        "RANDOM_VARIABLE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLqRTrLTnyDR"
      },
      "source": [
        "## 1. Scikit-Learn and Decision Trees ##\n",
        "\n",
        "You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) (+ [Additional information](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7d5K-BdnyDS"
      },
      "source": [
        "**1.1** Load the breast cancer dataset using the scikit learn library and split the dataset into train and test set using the appropriate function. Use 33% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "id": "NfF54h6anyDS",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4b873328ea05f6ef9c08827168c7b835",
          "grade": false,
          "grade_id": "cell-1f0c2f3918333cf6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state= RANDOM_VARIABLE)\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "FiOtzHkpnyDT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3603b2ba8916ffdad9e9c53f31546b4c",
          "grade": true,
          "grade_id": "cell-3f43c895ceaf57a9",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of train set:381\n",
            "Size of test set:188\n",
            "Unique classes:2\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of train set:{}\".format(len(y_train)))\n",
        "print(\"Size of test set:{}\".format(len(y_test)))\n",
        "print(\"Unique classes:{}\".format(len(set(y_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "JuW_lKVFnyDU",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "62285a7bd3ab59718b89f7e09de0fea4",
          "grade": false,
          "grade_id": "cell-1ce621a108e76a15",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "\n",
        "```\n",
        "Size of train set:381  \n",
        "Size of test set:188  \n",
        "Unique classes:2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUB8sl0NnyDV"
      },
      "source": [
        "**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "id": "nPQFaOhLnyDW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "17197b62614427a979fcbab7ed2734dd",
          "grade": false,
          "grade_id": "cell-a7fa1d29509eb2a1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "classifier_gini = DecisionTreeClassifier(random_state= RANDOM_VARIABLE) # criterion= \"gini\" by default\n",
        "classifier_igain = DecisionTreeClassifier(criterion=\"entropy\", random_state= RANDOM_VARIABLE)\n",
        "\n",
        "classifier_gini.fit(X_train,y_train)\n",
        "classifier_igain.fit(X_train,y_train)\n",
        "\n",
        "prediction_gini = classifier_gini.predict(X_test)\n",
        "prediction_igain = classifier_igain.predict(X_test)\n",
        "\n",
        "f_measure_gini = f1_score(y_test, prediction_gini)\n",
        "f_measure_igain = f1_score(y_test, prediction_igain)\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "qToIpGtnnyDX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6d9aab4355c27c346f7e6548f233e758",
          "grade": true,
          "grade_id": "cell-09657a82bf4028c4",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "971906be-59d1-412b-8cbd-c48f36fb104b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F-Measure Gini: 0.9372384937238494\n",
            "F-Measure Information Gain: 0.9596774193548386\n"
          ]
        }
      ],
      "source": [
        "print(\"F-Measure Gini: {}\".format(f_measure_gini))\n",
        "print(\"F-Measure Information Gain: {}\".format(f_measure_igain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hn9nblQ5nyDY",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f3facbbef0dd8f25ad12bfec7c174818",
          "grade": false,
          "grade_id": "cell-b0d8630f3b764cf3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "\n",
        "```\n",
        "F-Measure Gini: 0.9372384937238494\n",
        "F-Measure Information Gain: 0.9596774193548386\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "31Iyi9SJnyDZ",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f2532168d16e8c9bffba3d7d8e1efce7",
          "grade": false,
          "grade_id": "cell-591ba122016b6db5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**1.3** Find the maximum depth reached by the tree that used the Gini impurity. Train multiple classifiers by modifying the max_depth within the range from 1 to maximum depth and save the f1 scores to the corresponding list of the *fscores* dictionary (one list for training set and one for test set). Before appending the scores to the corresponding list, multiply them by 100, and round the values to 2 decimals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "id": "U7gSfRu_nyDa",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54cf257e90a3cb5877db81297bedd45c",
          "grade": false,
          "grade_id": "cell-31c58b6161a3907d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "depth = classifier_gini.get_depth()\n",
        "fscores = {}\n",
        "fscores['train'] = []\n",
        "fscores['test'] = []\n",
        "\n",
        "for i in range(1,depth+1):\n",
        "    clf = DecisionTreeClassifier(max_depth=i, random_state=RANDOM_VARIABLE).fit(X_train, y_train)\n",
        "    pred_train = clf.predict(X_train)\n",
        "    pred_test = clf.predict(X_test)\n",
        "    f1_train = round(f1_score(y_train, pred_train)*100, 2)\n",
        "    f1_test = round(f1_score(y_test, pred_test)*100, 2)\n",
        "    fscores['train'].append(f1_train)\n",
        "    fscores['test'].append(f1_test)\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "2395Por-nyDa",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "70a249937f2f690c6ce855debaed204c",
          "grade": true,
          "grade_id": "cell-0c300109423f53b9",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "02203fa9-4930-428f-d796-da5dbfaa41a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
            "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n"
          ]
        }
      ],
      "source": [
        "print(\"Fscores Train: {}\".format(fscores['train']))\n",
        "print(\"Fscores Test:  {}\".format(fscores['test']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f37yzYcbnyDb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3db472d2b9db7a42cc012cd96fdeb499",
          "grade": false,
          "grade_id": "cell-75789627f20d2c94",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "```\n",
        "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
        "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4stz0V9knyDd",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bca7d4c160c767d27a09b4620d27d56e",
          "grade": false,
          "grade_id": "cell-5906e6d5efa70282",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**1.4** Compare the results from the train set with the results from the test set. What do you notice? How are you going to choose the max_depth of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "kwtDaX3JnyDe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "424ac10e4e22ca9e32207deee3bf0f57",
          "grade": true,
          "grade_id": "cell-c9c6ea0e40d98b83",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "We can observe that in the train set, we get better f1 scores with greater max_depth. Eventually, for max_depth= 7 we get f1_score=1 which means that the model, perfectly classifies each observation from the training set, into the correct class. On the other hand, on the test set, we get the best f1 score for max_depth=3, while for max_depth > 3, the f1 scores, deteriorate. That is because the model starts overfitting, and thus, it performs worse in the test set. In my opinion, the best choice is max_depth =3, because the model performs almost equally well on the train and the test set and therefore, it generalizes better. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "PIw1fVFenyDe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "217666fcc2e383d6f2c1904c9d6a71be",
          "grade": false,
          "grade_id": "cell-9ef42e6c90ea2ffe",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2.0 Pipelines ##\n",
        "\n",
        "**2.1** In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7jJW-avitO9E"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "data=pd.read_csv('./income.csv')\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "train_set = data.iloc[:,:-1]\n",
        "y_train = data[\"income\"].values\n",
        "# any other code you need\n",
        "\n",
        "data_test = pd.read_csv('./income_test.csv')\n",
        "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "test_set = data_test.iloc[:,:-1]\n",
        "y_test = data_test['income'].values\n",
        "\n",
        "# any other code you need\n",
        "# End CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akVGpGHDuav4"
      },
      "source": [
        "**2.2** Create and test your pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pv6z98huuZ6M"
      },
      "outputs": [],
      "source": [
        "#Your pipeline\n",
        "numeric_columns= ['age', 'fnlwgt', 'education_num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "cat_columns= ['workclass','race','marital-status','occupation','relationship']\n",
        "ordinal1= OrdinalEncoder(categories=[['Preschool','Dropout', 'HS-grad', 'CommunityCollege', 'Bachelors', 'Masters', 'Doctorate']])\n",
        "ordinal2= OrdinalEncoder(categories= 'auto')\n",
        "standard = StandardScaler()\n",
        "column_transforms = ColumnTransformer([('OneHot', OneHotEncoder(handle_unknown='ignore'), cat_columns), ('Ordinal', ordinal1, ['education']),\n",
        "                                         ('Ordinal2', ordinal2, ['sex']), ('Standard', standard, numeric_columns)])\n",
        "\n",
        "\n",
        "imputer= SimpleImputer(strategy= 'mean')\n",
        "tree = DecisionTreeClassifier(criterion='entropy' , max_features= None , random_state= RANDOM_VARIABLE)\n",
        "\n",
        "clf = Pipeline([('preprocessing', column_transforms),('imputer', imputer), ('classifier', tree)]) \n",
        "clf.fit(train_set,y_train)\n",
        "y_predict =  clf.predict(test_set)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3uaArYmQvKcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score Accuracy: 0.811\n",
            "Model score F1 Weighted: 0.811\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test, y_predict))\n",
        "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test, y_predict,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz_MWnYY2r3-"
      },
      "source": [
        "**2.3** Perform a gooood grid search to find the best parameters for your pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "RNECyUFtnyDf",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "152ab2dd6861b198b879a78ebadc4ee4",
          "grade": true,
          "grade_id": "cell-dd950ab2eb40d8a4",
          "locked": false,
          "points": 45,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "7955851a-cad6-4132-bd66-587543300978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
            "Best params:\n",
            "{'classifier__criterion': 'gini', 'classifier__max_depth': 12, 'classifier__max_features': 0.5, 'classifier__min_samples_leaf': 21, 'imputer__strategy': 'mean'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'imputer__strategy':['mean', 'median'],\n",
        "    'classifier__max_depth':[12, 17, 30],\n",
        "    'classifier__criterion':['gini', 'entropy'],\n",
        "    'classifier__min_samples_leaf':[5, 17, 21],\n",
        "    'classifier__max_features': [None, 0.25, 0.5, 0.75]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV( clf, param_grid, cv = 5, verbose=1, scoring= 'accuracy', n_jobs= 8)\n",
        "grid_search.fit(train_set, y_train)\n",
        "y_predict_grid =  grid_search.predict(test_set)\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OhE0haFuw57D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score Accuracy: 0.851\n",
            "Model score F1 Weighted: 0.844\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test,y_predict_grid))\n",
        "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test,y_predict_grid,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f_lIQ1-wnyDg",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ee9d4c2635307395bdef2efb941106ae",
          "grade": false,
          "grade_id": "cell-2c3327274958bbad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**2.4** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following \n",
        "- How do you handle missing values and why\n",
        "- How do you handle categorical variables and why\n",
        "- Any further preprocessing steps\n",
        "- How do you evaluate your model and how did you choose its parameters \n",
        "- Report any additional results and comments on your approach.\n",
        "\n",
        "You should achieve at least 85% accuracy score and 84% f1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "76FF0gYVnyDh",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1aaf3ddda45b52c2e43089b082d030f1",
          "grade": true,
          "grade_id": "cell-80274fd09b80518c",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "First, I split the columns of the dataset into numeric and categorical columns and left out the 'education' and 'sex' columns in order to handle them separately. For the categorical columns, I used OneHotEncoder, because DecisionTreeClassifiers from scikit-learn can not handle categorical data. For the 'education' column I used OrdinalEncoder and specified the categories in order to make the transformations in the right order. For the 'sex' column I also used an OrdinalEncoder with categories set to 'auto' (It makes no difference). I also used a StandardScaler for the numeric columns, to fix the variance. In order to perform these separate tasks to different columns, I used a column transformer. After all the data is numeric, I used a SimpleImputer, in order to handle missing values. I defined a DecisionTreeClassifier and then I set up the Pipeline. \n",
        "In order to find the best parameters for the model, I used GridSearchCV and tried out different strategies for the imputer, and different parameters for the classifier. I tried many different combinations, but in order to keep the runtime relatively low, I left a subset of the original options I used in the param_grid. The highest accuracy and weighted F1 score my model achieved was 85.1% and 8.44% respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mNqPY_yanyDj",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8cef3f333ab449ed91b81ea96695e712",
          "grade": false,
          "grade_id": "cell-555d20216f9bbec2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 3.0 Common Issues ## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USyDSnDCnyDk"
      },
      "source": [
        "**3.0** Run the following code to define a DecisionTreeModel and load the **income** dataset only with the numerical variables. Then, answer the following questions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "G9M3JhlpnyDl",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ae0f57b86252cc38b02cac3d05e08bbf",
          "grade": false,
          "grade_id": "cell-d7f58621bad12aad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score accuracy: 0.811\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
        "data = pd.read_csv('income.csv',usecols=columns)\n",
        "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
        "# Convert target variable to 0 and 1\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "# Create X and y\n",
        "X_train = data.drop([\"income\"],axis=1)\n",
        "y_train = data['income'].values\n",
        "X_test = data_test.drop([\"income\"],axis=1)\n",
        "y_test = data_test['income'].values\n",
        "# Classifier\n",
        "classifier = DecisionTreeClassifier(min_samples_leaf=4)\n",
        "classifier.fit(X_train,y_train)\n",
        "accuracy_score = accuracy_score(y_test,y_predict)\n",
        "print(\"Model score accuracy: %.3f\" % accuracy_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Yal5vVVInyDo",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c3981752b539236e99415ab6e2cbea1f",
          "grade": false,
          "grade_id": "cell-9b18d6c4e381a9f5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.1** Evaluate the classifier using at least three evaluation metrics except accuracy_score and f1 (weighted)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "id": "4HaPGUuUnyDo",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "12b88026c150b617074a5c06fea36b73",
          "grade": true,
          "grade_id": "cell-905e7dceeb4172c3",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10295  1248]\n",
            " [ 1957  1815]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, average_precision_score, f1_score, confusion_matrix\n",
        "y_predict = classifier.predict(X_test) \n",
        "\n",
        "# BEGIN CODE HERE\n",
        "metric1 = balanced_accuracy_score(y_test,y_predict)\n",
        "metric2 = average_precision_score(y_test,y_predict)\n",
        "metric3 = f1_score(y_test,y_predict )\n",
        "metric4 = confusion_matrix(y_test, y_predict)\n",
        "print(metric4)\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H03BYlAC6B5u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score Metric 1: 0.687\n",
            "Model score Metric 2: 0.413\n",
            "Model score Metric 3: 0.531\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "YJxhaPxdnyDr",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "361d4753f3c8491a34ff55b6fa3a49b5",
          "grade": false,
          "grade_id": "cell-1f23f3e27600f019",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.2** Do you notice any problems with the classifier? If so, what can you do to change this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "PIEyNQJsnyDt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "baff993106fd2b655fd47d05c75ea4ce",
          "grade": true,
          "grade_id": "cell-d60d7e6175d184e9",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "Problems:\n",
        "We can see that the model has a pretty good accuracy score (81.9%), but the balanced accuracy score is substantially worse (68.8%). The other metrics (average precision score, f1 score) also point out that the model is not performing well. Due to the above, I suspect that the dataset is imbalanced. By printing the confusion matrix, I can make better conclusions. The training set has 7841 samples in one class (class 1) and 24727 in the other (class 0). In the testing set we have a similar situation (3772 samples in class 1 and 11543 samples in class 0). We know that Decision Tree Classifiers don't handle imbalanced datasets very well. The conclusion we can draw is that the model is taking advantage of the imbalanced dataset and that is why it appears to be doing well (accuracy score), when in reality, it is only doing well in classifying samples from the majority class.\n",
        "\n",
        "Solutions:\n",
        "Two techniques we could use is Synthetic Minority Oversampling (SMOTE) of the minority class (class 1) or Random Undersampling of the majority class (class 0). A better solution, because we are using all the data we are given (without leaving valuable data samples unused and without synthetic samples) is using a weights for the two classes, by providing the class_weight arguement in the DecisionTreeClassifier.\n",
        "Finally, we could use stratification. In order to implement this technique, I joined the two datasets and used sklearn's train_test_split() with the 'stratify' parameter. I passed test_size = 0.32 so that the train and test sets have the same sizes as they did originally. \n",
        "I also did GridSearch in order tp find the best parameters for the classifier. Eventually, I can see a small improvement in the metrics I used and the accuracy achieved is higher than 82%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WCN7E_ctnyDu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "747645b33cb4f5c14796504fac6bf3ce",
          "grade": false,
          "grade_id": "cell-89715acd6c51b332",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.3** Implement your solution using the cells below. Report your results and the process you followed. You are reccommended to use stratification and grid search. You should only have to increase a little bit the metrics you calculated above, and also reach an accuracy score higher than 82%!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "id": "g9Wzx0bknyDv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ccd1d12620f1a3e1c7b026b862056546",
          "grade": true,
          "grade_id": "cell-f44811f1e99ee41e",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params:\n",
            "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 4}\n",
            "0.8364336531557992\n"
          ]
        }
      ],
      "source": [
        "# # BEGIN CODE HERE\n",
        "columns1 = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
        "data = pd.read_csv('income.csv',usecols=columns1)\n",
        "data_test = pd.read_csv('income_test.csv',usecols=columns1)\n",
        "# Convert target variable to 0 and 1\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "data_full = data.append(data_test, ignore_index=True)\n",
        "y = data_full[\"income\"]\n",
        "X = data_full.drop([\"income\"],axis=1)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.32, shuffle= True ,stratify = y)\n",
        "\n",
        "\n",
        "tree_classifier = DecisionTreeClassifier(min_samples_leaf=4)\n",
        "\n",
        "\n",
        "param_grid1 = {\n",
        "    'criterion':['gini', 'entropy'],\n",
        "    'max_depth':[10, 17, 25, 30],\n",
        "    'min_samples_leaf':[4, 12, 15, 20],\n",
        "    'max_features':[None, 0.25, 0.5]\n",
        "    \n",
        "}\n",
        "\n",
        "grid_search1 = GridSearchCV( tree_classifier, param_grid1, cv = 5)\n",
        "grid_search1.fit(X_train, y_train)\n",
        "final_prediction =  grid_search1.predict(X_test)\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(grid_search1.best_params_)\n",
        "print(accuracy_score(y_test,final_prediction))\n",
        "metric1 = balanced_accuracy_score(y_test,final_prediction)\n",
        "metric2 = average_precision_score(y_test,final_prediction)\n",
        "metric3 = f1_score(y_test,final_prediction)\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HoDBPL6n6LLI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score Metric 1: 0.698\n",
            "Model score Metric 2: 0.484\n",
            "Model score Metric 3: 0.559\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DecisionTrees.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b75e1fc7662d1d26acfadeff55dd73fae73e7401a313ed24a759d447e5c9b396"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
